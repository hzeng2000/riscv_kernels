

// Auto-generated test runner for quantize_row_q8_0 on th1520
// RVV Version: rvv_0.7.1
// Generated by VectorWeaver

#include <iostream>
#include <vector>
#include <string>
#include <random>
#include <chrono>
#include <cmath>
#include <iomanip>
#include <cassert>

#include "../common/common_defs.h"
#include "quantize_row_q8_0_kernels.h"

#if defined(__riscv_v) || defined(__riscv_xtheadvector)
#include <riscv_vector.h>
#endif

// === Test Configuration ===
struct TestConfig {
    int n = 4096;
    int runs = 1000;
};

// === Test Entry ===
struct TestEntry {
    std::string name;
    quantize_q8_0_t func;
};

// === Helper Functions ===
std::string short_name(const std::string& full_name) {
    const std::string prefix = "quantize_row_q8_0_";
    if (full_name.find(prefix) == 0) {
        return full_name.substr(prefix.length());
    }
    return full_name;
}

void generate_random_floats(std::vector<float>& vec) {
    std::mt19937 gen(1337);
    std::uniform_real_distribution<> dis(-1.0f, 1.0f);
    for (float& val : vec) { val = dis(gen); }
}

// === Scalar Baseline ===
void quantize_row_q8_0_scalar(const float * GGML_RESTRICT x, block_q8_0 * GGML_RESTRICT y, int64_t k) {
    const int nb = k / QK8_0;
    for (int i = 0; i < nb; i++) {
        float amax = 0.0f;
        for (int j = 0; j < QK8_0; j++) {
            amax = std::max(amax, std::abs(x[i*QK8_0 + j]));
        }
        const float d = amax / 127.0f;
        const float id = d ? 1.0f/d : 0.0f;
        y[i].d = GGML_FP32_TO_FP16(d);
        for (int j = 0; j < QK8_0; j++) {
            y[i].qs[j] = (int8_t)roundf(x[i*QK8_0 + j] * id);
        }
    }
}

void print_help(char* app_name) {
    std::cout << "Usage: " << app_name << " [options]\n";
    std::cout << "  -n <size>    Data size (default: 4096)\n";
    std::cout << "  -r <runs>    Number of runs (default: 1000)\n";
    std::cout << "  --help       Show this help\n";
}

void parse_args(int argc, char** argv, TestConfig& config) {
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        if (arg == "-n") { config.n = std::stoi(argv[++i]); }
        else if (arg == "-r") { config.runs = std::stoi(argv[++i]); }
        else if (arg == "--help") { print_help(argv[0]); exit(0); }
    }
}

double check_block_q8_0_correctness(const std::vector<block_q8_0>& baseline, const std::vector<block_q8_0>& result) {
    double max_diff = 0.0;
    for (size_t i = 0; i < baseline.size(); ++i) {
        // Check d values
        float d_base = GGML_FP16_TO_FP32(baseline[i].d);
        float d_test = GGML_FP16_TO_FP32(result[i].d);
        max_diff = std::max(max_diff, (double)std::abs(d_base - d_test));
        
        // Check qs values
        for (int j = 0; j < QK8_0; ++j) {
            max_diff = std::max(max_diff, (double)std::abs(baseline[i].qs[j] - result[i].qs[j]));
        }
    }
    return max_diff;
}

int main(int argc, char** argv) {
    TestConfig config;
    parse_args(argc, argv, config);
    
    std::cout << "=== quantize_row_q8_0 Benchmark on th1520 ===" << std::endl;
    std::cout << "RVV Version: rvv_0.7.1" << std::endl;
    std::cout << "Data Size: " << config.n << ", Runs: " << config.runs << std::endl;
    std::cout << std::endl;
    
    // Setup test data
    std::vector<float> x_f32(config.n);
    generate_random_floats(x_f32);
    std::vector<block_q8_0> y_result(config.n / QK8_0);
    std::vector<block_q8_0> y_baseline(config.n / QK8_0);
    
    // Register all kernels
    std::vector<TestEntry> all_tests;
    all_tests.push_back({"Scalar (baseline)", quantize_row_q8_0_scalar});
    
#if defined(__riscv_v)
    all_tests.push_back({"RVV Intrinsics", quantize_row_q8_0_rvv_intrinsics});
#endif


#if defined(__RVV_ASM_XTHEAD)
    all_tests.push_back({"quantize_row_q8_0_baseline", quantize_row_q8_0_baseline});
    all_tests.push_back({"quantize_row_q8_0_asm_unroll2", quantize_row_q8_0_asm_unroll2});
#endif

    // === Step 1: Correctness Check ===
    std::cout << "=== Correctness Verification ===" << std::endl;
    
    quantize_row_q8_0_scalar(x_f32.data(), y_baseline.data(), config.n);
    
    bool all_correct = true;
    for (auto const& test : all_tests) {
        test.func(x_f32.data(), y_result.data(), config.n);
        double max_diff = check_block_q8_0_correctness(y_baseline, y_result);
        bool correct = max_diff < 1.0; // Allow 1 unit difference in qs
        if (!correct) all_correct = false;
        std::cout << "  " << test.name << ": " << (correct ? "PASS" : "FAIL") 
                  << " (max_diff=" << max_diff << ")" << std::endl;
    }
    
    if (!all_correct) {
        std::cerr << "\n[WARNING] Some kernels failed correctness check!\n" << std::endl;
    }
    
    // === Step 2: Performance Test ===
    std::cout << "\n=== Performance Benchmark ===" << std::endl;
    std::cout << std::left << std::setw(50) << "Kernel Variant"
              << std::setw(18) << "Avg Time (us)"
              << "Speedup" << std::endl;
    std::cout << std::string(80, '-') << std::endl;
    
    double baseline_time = 0.0;
    for (size_t i = 0; i < all_tests.size(); ++i) {
        auto const& test = all_tests[i];
        
        // Warmup
        for (int w = 0; w < 10; ++w) {
            test.func(x_f32.data(), y_result.data(), config.n);
        }
        
        auto start = std::chrono::high_resolution_clock::now();
        for (int r = 0; r < config.runs; ++r) {
            test.func(x_f32.data(), y_result.data(), config.n);
        }
        auto end = std::chrono::high_resolution_clock::now();
        
        double avg_time = std::chrono::duration<double, std::micro>(end - start).count() / config.runs;
        
        if (i == 0) baseline_time = avg_time;
        double speedup = baseline_time / avg_time;
        
        std::cout << std::left << std::setw(50) << short_name(test.name)
                  << std::fixed << std::setprecision(4) << std::setw(18) << avg_time
                  << std::setprecision(4) << speedup << "x" << std::endl;
    }
    
    return 0;
}