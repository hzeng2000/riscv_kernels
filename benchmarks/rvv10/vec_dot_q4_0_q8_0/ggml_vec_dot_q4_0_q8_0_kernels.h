#pragma once
// Auto-generated header for ggml_vec_dot_q4_0_q8_0 on sg2044
// RVV Version: rvv_1.0
// Generated by VectorWeaver

#include "../common/common_defs.h"
#include <cstdint>
#include <cmath>

// Function pointer type
using vec_dot_q4_0_q8_0_t = void (*)(int n, float *s, const void *vx, const void *vy);

// === Kernel Declarations ===

// Baseline scalar implementation
void ggml_vec_dot_q4_0_q8_0_scalar(int n, float *s, const void *vx, const void *vy);

// RVV implementations
#if defined(__riscv_v)
void ggml_vec_dot_q4_0_q8_0_rvv_intrinsics(int n, float *s, const void *vx, const void *vy);
#endif

#if defined(__RVV_ASM_STD)
void ggml_vec_dot_q4_0_q8_0_baseline(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_f64(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_f64(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_interleaved(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_interleaved_f64(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_batch4(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_f64_batch4(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_f64_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_f64_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_interleaved_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_interleaved_f64_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_f64_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_interleaved_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_interleaved_f64_split_macc(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_split_macc_batch4(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_f64_split_macc_batch4(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_f64_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_f64_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_interleaved_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll2_interleaved_f64_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_f64_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_interleaved_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_unroll4_interleaved_f64_split(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_split_batch4(int n, float *s, const void *vx, const void *vy);
void ggml_vec_dot_q4_0_q8_0_asm_f64_split_batch4(int n, float *s, const void *vx, const void *vy);
#endif
