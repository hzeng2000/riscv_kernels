

// Auto-generated test runner for ggml_rmsnorm_f32 on sg2044
// RVV Version: rvv_1.0
// Generated by VectorWeaver

#include <iostream>
#include <vector>
#include <string>
#include <random>
#include <chrono>
#include <cmath>
#include <iomanip>
#include <cassert>

#include "../common/common_defs.h"
#include "ggml_rmsnorm_f32_kernels.h"

#if defined(__riscv_v) || defined(__riscv_xtheadvector)
#include <riscv_vector.h>
#endif

// === Test Configuration ===
struct TestConfig {
    int n = 4096;
    int runs = 1000;
    float eps = 1e-5f;
};

// === Test Entry ===
struct TestEntry {
    std::string name;
    rmsnorm_f32_t func;
};

// === Helper Functions ===
std::string short_name(const std::string& full_name) {
    const std::string prefix = "ggml_rmsnorm_f32_";
    if (full_name.find(prefix) == 0) {
        return full_name.substr(prefix.length());
    }
    return full_name;
}

void generate_random_floats(std::vector<float>& vec) {
    std::mt19937 gen(1337);
    std::uniform_real_distribution<> dis(-1.0f, 1.0f);
    for (float& val : vec) { val = dis(gen); }
}

// === Scalar Baseline ===
void ggml_rmsnorm_f32_scalar(int n, float *y, const float *x, float eps) {
    double sum_sq = 0.0;
    for (int i = 0; i < n; ++i) {
        sum_sq += (double)x[i] * x[i];
    }
    const float mean = (float)(sum_sq / n);
    const float scale = 1.0f / sqrtf(mean + eps);
    for (int i = 0; i < n; ++i) {
        y[i] = x[i] * scale;
    }
}

void print_help(char* app_name) {
    std::cout << "Usage: " << app_name << " [options]\n";
    std::cout << "  -n <size>    Data size (default: 4096)\n";
    std::cout << "  -r <runs>    Number of runs (default: 1000)\n";
    std::cout << "  --help       Show this help\n";
}

void parse_args(int argc, char** argv, TestConfig& config) {
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        if (arg == "-n") { config.n = std::stoi(argv[++i]); }
        else if (arg == "-r") { config.runs = std::stoi(argv[++i]); }
        else if (arg == "--help") { print_help(argv[0]); exit(0); }
    }
}

double check_array_correctness(const std::vector<float>& baseline, const std::vector<float>& result) {
    double max_diff = 0.0;
    for (size_t i = 0; i < baseline.size(); ++i) {
        max_diff = std::max(max_diff, (double)std::abs(baseline[i] - result[i]));
    }
    return max_diff;
}

int main(int argc, char** argv) {
    TestConfig config;
    parse_args(argc, argv, config);
    
    std::cout << "=== ggml_rmsnorm_f32 Benchmark on sg2044 ===" << std::endl;
    std::cout << "RVV Version: rvv_1.0" << std::endl;
    std::cout << "Data Size: " << config.n << ", Runs: " << config.runs << std::endl;
    std::cout << std::endl;
    
    // Setup test data
    std::vector<float> x_f32(config.n);
    generate_random_floats(x_f32);
    std::vector<float> y_result(config.n);
    std::vector<float> y_baseline(config.n);
    
    // Register all kernels
    std::vector<TestEntry> all_tests;
    all_tests.push_back({"Scalar (baseline)", ggml_rmsnorm_f32_scalar});
    

#if defined(__riscv_v)

    all_tests.push_back({"RVV Intrinsics", ggml_rmsnorm_f32_rvv_intrinsics});
#endif


#if defined(__RVV_ASM_STD)

    all_tests.push_back({"ggml_rmsnorm_f32_baseline", ggml_rmsnorm_f32_baseline});
    all_tests.push_back({"ggml_rmsnorm_f32_asm_unroll2", ggml_rmsnorm_f32_asm_unroll2});
    all_tests.push_back({"ggml_rmsnorm_f32_asm_unroll2_interleaved", ggml_rmsnorm_f32_asm_unroll2_interleaved});
    all_tests.push_back({"ggml_rmsnorm_f32_asm_unroll4", ggml_rmsnorm_f32_asm_unroll4});
    all_tests.push_back({"ggml_rmsnorm_f32_asm_unroll4_interleaved", ggml_rmsnorm_f32_asm_unroll4_interleaved});
#endif

    // === Step 1: Correctness Check ===
    std::cout << "=== Correctness Verification ===" << std::endl;
    
    ggml_rmsnorm_f32_scalar(config.n, y_baseline.data(), x_f32.data(), config.eps);
    
    const float tolerance = 1e-5f;
    bool all_correct = true;
    for (auto const& test : all_tests) {
        test.func(config.n, y_result.data(), x_f32.data(), config.eps);
        double max_diff = check_array_correctness(y_baseline, y_result);
        bool correct = max_diff < tolerance;
        if (!correct) all_correct = false;
        std::cout << "  " << test.name << ": " << (correct ? "PASS" : "FAIL") 
                  << " (max_diff=" << max_diff << ")" << std::endl;
    }
    
    if (!all_correct) {
        std::cerr << "\n[WARNING] Some kernels failed correctness check!\n" << std::endl;
    }
    
    // === Step 2: Performance Test ===
    std::cout << "\n=== Performance Benchmark ===" << std::endl;
    std::cout << std::left << std::setw(50) << "Kernel Variant"
              << std::setw(18) << "Avg Time (us)"
              << "Speedup" << std::endl;
    std::cout << std::string(80, '-') << std::endl;
    
    double baseline_time = 0.0;
    for (size_t i = 0; i < all_tests.size(); ++i) {
        auto const& test = all_tests[i];
        
        // Warmup
        for (int w = 0; w < 10; ++w) {
            test.func(config.n, y_result.data(), x_f32.data(), config.eps);
        }
        
        auto start = std::chrono::high_resolution_clock::now();
        for (int r = 0; r < config.runs; ++r) {
            test.func(config.n, y_result.data(), x_f32.data(), config.eps);
        }
        auto end = std::chrono::high_resolution_clock::now();
        
        double avg_time = std::chrono::duration<double, std::micro>(end - start).count() / config.runs;
        
        if (i == 0) baseline_time = avg_time;
        double speedup = baseline_time / avg_time;
        
        std::cout << std::left << std::setw(50) << short_name(test.name)
                  << std::fixed << std::setprecision(4) << std::setw(18) << avg_time
                  << std::setprecision(4) << speedup << "x" << std::endl;
    }
    
    return 0;
}