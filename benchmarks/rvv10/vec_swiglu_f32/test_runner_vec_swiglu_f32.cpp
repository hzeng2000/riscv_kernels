// Auto-generated test runner for ggml_vec_swiglu_f32 on sg2044
// RVV Version: rvv_1.0
// Generated by VectorWeaver

#include <iostream>
#include <vector>
#include <string>
#include <random>
#include <chrono>
#include <cmath>
#include <iomanip>
#include <cassert>

#include "ggml_vec_swiglu_f32_kernels.h"

#if defined(__riscv_v) || defined(__riscv_xtheadvector)
#include <riscv_vector.h>
#endif

// === Test Configuration ===
struct TestConfig {
    int n = 4096;
    int runs = 1000;
};

// === Test Entry ===
struct TestEntry {
    std::string name;
    vec_swiglu_f32_t func;
};

// === Helper Functions ===
void generate_random_floats(std::vector<float>& vec) {
    std::mt19937 gen(1337);
    std::uniform_real_distribution<> dis(-1.0f, 1.0f);
    for (float& val : vec) { val = dis(gen); }
}

// === Scalar Baseline ===

void ggml_vec_swiglu_f32_scalar(const int n, float * y, const float * x, const float * g) {
    for (int i = 0; i < n; ++i) {
        y[i] = (x[i] / (1.0f + expf(-x[i]))) * g[i];
    }
}

void print_help(char* app_name) {
    std::cout << "Usage: " << app_name << " [options]\n";
    std::cout << "  -n <size>    Data size (default: 4096)\n";
    std::cout << "  -r <runs>    Number of runs (default: 1000)\n";
    std::cout << "  --help       Show this help\n";
}

void parse_args(int argc, char** argv, TestConfig& config) {
    for (int i = 1; i < argc; ++i) {
        std::string arg = argv[i];
        if (arg == "-n") { config.n = std::stoi(argv[++i]); }
        else if (arg == "-r") { config.runs = std::stoi(argv[++i]); }
        else if (arg == "--help") { print_help(argv[0]); exit(0); }
    }
}

int main(int argc, char** argv) {
    TestConfig config;
    parse_args(argc, argv, config);
    
    std::cout << "=== ggml_vec_swiglu_f32 Benchmark on sg2044 ===" << std::endl;
    std::cout << "RVV Version: rvv_1.0" << std::endl;
    std::cout << "Data Size: " << config.n << ", Runs: " << config.runs << std::endl;
    std::cout << std::endl;
    
    // Setup test data

    std::vector<float> x_f32(config.n);
    std::vector<float> g_f32(config.n);
    generate_random_floats(x_f32);
    generate_random_floats(g_f32);
    std::vector<float> y_result(config.n);
    std::vector<float> y_baseline(config.n);

    
    // Register all kernels
    std::vector<TestEntry> all_tests;
    all_tests.push_back({"Scalar (baseline)", ggml_vec_swiglu_f32_scalar});
    
#if defined(__riscv_v)
    all_tests.push_back({"ggml_vec_swiglu_f32_rvv_intrinsics", ggml_vec_swiglu_f32_rvv_intrinsics});
#endif

#if defined(__RVV_ASM_STD)
    all_tests.push_back({"u1_ser", ggml_vec_swiglu_f32_baseline});
    all_tests.push_back({"u2_ser", ggml_vec_swiglu_f32_asm_unroll2});
    all_tests.push_back({"u2_int", ggml_vec_swiglu_f32_asm_unroll2_interleaved});
    all_tests.push_back({"u4_ser", ggml_vec_swiglu_f32_asm_unroll4});
    all_tests.push_back({"u4_int", ggml_vec_swiglu_f32_asm_unroll4_interleaved});
#endif

    // === Step 1: Correctness Check ===
    std::cout << "=== Correctness Verification ===" << std::endl;
    
    // Compute reference result using scalar baseline
    ggml_vec_swiglu_f32_scalar(config.n, y_baseline.data(), x_f32.data(), g_f32.data());
    
    const float tolerance = 1e-3f; // 相对误差容忍度
    bool all_correct = true;
    
    for (size_t i = 0; i < all_tests.size(); ++i) {
        auto const& test = all_tests[i];
        test.func(config.n, y_result.data(), x_f32.data(), g_f32.data());
        
        // 计算数组的平均相对误差
        double total_rel_error = 0.0;
        int error_count = 0;
        for (size_t j = 0; j < y_result.size(); ++j) {
            float abs_diff = std::abs(y_result[j] - y_baseline[j]);
            float rel_error = 0.0f;
            if (std::abs(y_baseline[j]) > 1e-6f) {
                rel_error = abs_diff / std::abs(y_baseline[j]);
            } else {
                rel_error = abs_diff;
            }
            total_rel_error += rel_error;
            if (rel_error > tolerance) {
                error_count++;
            }
        }
        double avg_rel_error = total_rel_error / y_result.size();
        
        bool is_correct = (error_count == 0);
        if (!is_correct) {
            all_correct = false;
            std::cout << "[FAIL] " << test.name 
                      << " - " << error_count << " elements failed, Avg Rel Error: " << avg_rel_error << std::endl;
        } else {
            std::cout << "[PASS] " << test.name 
                      << " (Avg Rel Error: " << std::scientific << avg_rel_error << ")" << std::endl;
        }
    }
    
    std::cout << std::endl;
    if (!all_correct) {
        std::cout << "ERROR: Some kernels failed correctness check!" << std::endl;
    }
    else {
        std::cout << "All kernels passed correctness check!" << std::endl;
        std::cout << std::endl;
    }

    // === Step 2: Performance Benchmark ===
    std::cout << "=== Performance Benchmark ===" << std::endl;
    std::cout << std::left << std::setw(40) << "Kernel"
              << std::setw(15) << "Time (us)"
              << "Speedup" << std::endl;
    std::cout << std::string(70, '-') << std::endl;
    
    double baseline_time = 0.0;
    for (size_t i = 0; i < all_tests.size(); ++i) {
        auto const& test = all_tests[i];
        float result = 0.0f;
        
        auto start = std::chrono::high_resolution_clock::now();
        for (int k = 0; k < config.runs; ++k) {
            test.func(config.n, y_result.data(), x_f32.data(), g_f32.data());
        }
        auto end = std::chrono::high_resolution_clock::now();
        
        double avg_time = std::chrono::duration<double, std::micro>(end - start).count() / config.runs;
        
        if (i == 0) baseline_time = avg_time;
        double speedup = baseline_time / avg_time;
        
        std::cout << std::left << std::setw(40) << test.name
                  << std::fixed << std::setprecision(2) << std::setw(15) << avg_time
                  << std::setprecision(2) << speedup << "x" << std::endl;
    }
    
    return 0;
}
